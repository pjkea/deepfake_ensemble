#!/usr/bin/env python3
"""
Ensemble Deepfake Detector - Individual Model Dashboard
Shows each model's prediction separately to leverage their different specializations

Models:
1. FSFM-3C (Wolowolo) - 4-class ViT - Best for: Spoofing, advanced manipulations
2. CemRoot - EfficientNetB7 + Attention - Best for: Diffusion models, AIGC
3. ViT-v2 (prithivMLmods) - ViT-base - Best for: Traditional deepfakes, ChatGPT gen
"""

import torch
import numpy as np
from PIL import Image
import argparse
import os
import sys

# Import individual detectors
from .fsfm_unified_detector import FSFM_UnifiedDetector
from .cemroot_detector import CemRootDetector
from .vit_detector import DeepFakeDetectorV2


class EnsembleDeepfakeDetector:
    """
    Ensemble detector showing individual model outputs
    No voting/aggregation - shows each model's specialty
    """

    def __init__(self, fsfm_config, cemroot_config, vit_config):
        """
        Initialize ensemble detector

        Args:
            fsfm_config: Dict with 'checkpoint', 'mean_std', 'device'
            cemroot_config: Dict with 'model_path', 'image_size'
            vit_config: Dict with 'model_name', 'cache_dir', 'device'
        """
        print("\n" + "="*70)
        print("INITIALIZING ENSEMBLE DEEPFAKE DETECTOR")
        print("="*70)

        # Initialize Model 1: FSFM-3C
        print("\n[1/3] Loading FSFM-3C Unified Detector...")
        self.fsfm = FSFM_UnifiedDetector(
            checkpoint_path=fsfm_config['checkpoint'],
            mean_std_path=fsfm_config['mean_std'],
            device=fsfm_config.get('device', 'cuda')
        )

        # Initialize Model 2: CemRoot
        print("\n[2/3] Loading CemRoot EfficientNet Detector...")
        self.cemroot = CemRootDetector(
            model_path=cemroot_config['model_path'],
            image_size=cemroot_config.get('image_size', 128)
        )

        # Initialize Model 3: ViT-v2
        print("\n[3/3] Loading ViT-v2 Detector...")
        self.vit = DeepFakeDetectorV2(
            model_name=vit_config.get('model_name', 'prithivMLmods/Deep-Fake-Detector-v2-Model'),
            cache_dir=vit_config.get('cache_dir', None),
            device=vit_config.get('device', 'cuda')
        )

        print("\n" + "="*70)
        print("‚úì ALL MODELS LOADED SUCCESSFULLY!")
        print("="*70 + "\n")

    def predict(self, image_path, cemroot_method='training_match'):
        """
        Get predictions from all 3 models individually

        Args:
            image_path: Path to image or PIL Image
            cemroot_method: Preprocessing method for CemRoot ('training_match' recommended)

        Returns:
            Dictionary with individual model predictions (no aggregation)
        """
        print(f"\nüîç Running individual model predictions on: {image_path}")

        # Get predictions from all models
        print("  [1/3] FSFM-3C predicting...")
        fsfm_result = self.fsfm.predict(image_path, return_all_probs=True)

        print("  [2/3] CemRoot predicting...")
        cemroot_result = self.cemroot.predict(
            image_path,
            method=cemroot_method,
            return_all_probs=True
        )

        print("  [3/3] ViT-v2 predicting...")
        vit_result = self.vit.predict(image_path, return_all_probs=True)

        # Normalize to binary (Real vs Fake) for summary
        fsfm_is_fake = fsfm_result['predicted_class'] != 0
        cemroot_is_fake = cemroot_result['predicted_class'] == 0
        vit_is_fake = "Deepfake" in vit_result['predicted_label']

        # Build result showing each model's output
        result = {
            'models': {
                'fsfm': {
                    'name': 'FSFM-3C (4-class)',
                    'prediction': fsfm_result['predicted_label'],
                    'confidence': fsfm_result['confidence'],
                    'is_fake': fsfm_is_fake,
                    'all_probabilities': fsfm_result.get('all_probabilities', {}),
                    'specialty': 'Spoofing, Physical attacks, Advanced manipulations'
                },
                'cemroot': {
                    'name': 'CemRoot (EfficientNet)',
                    'prediction': cemroot_result['predicted_label'],
                    'confidence': cemroot_result['confidence'],
                    'is_fake': cemroot_is_fake,
                    'all_probabilities': cemroot_result.get('all_probabilities', {}),
                    'preprocessing': cemroot_method,
                    'specialty': 'Diffusion models, AIGC, Stable Diffusion'
                },
                'vit': {
                    'name': 'ViT-v2 (Transformers)',
                    'prediction': vit_result['predicted_label'],
                    'confidence': vit_result['confidence'],
                    'is_fake': vit_is_fake,
                    'all_probabilities': vit_result.get('all_probabilities', {}),
                    'specialty': 'Traditional deepfakes, ChatGPT/Gemini generation'
                }
            },
            'summary': {
                'models_detecting_fake': sum([fsfm_is_fake, cemroot_is_fake, vit_is_fake]),
                'total_models': 3,
                'detected_by': []
            }
        }

        # Track which models detected fake
        if fsfm_is_fake:
            result['summary']['detected_by'].append('FSFM-3C')
        if cemroot_is_fake:
            result['summary']['detected_by'].append('CemRoot')
        if vit_is_fake:
            result['summary']['detected_by'].append('ViT-v2')

        return result


def print_ensemble_result(result):
    """Pretty print individual model results"""
    print("\n" + "="*70)
    print("üéØ ENSEMBLE DEEPFAKE DETECTION - INDIVIDUAL MODEL OUTPUTS")
    print("="*70)

    # Summary
    fake_count = result['summary']['models_detecting_fake']
    total = result['summary']['total_models']

    print(f"\nüìä SUMMARY: {fake_count}/{total} models detected FAKE")

    if fake_count == 0:
        print("‚úÖ All models agree: REAL image")
    elif fake_count == total:
        print("üö® All models agree: FAKE image")
    else:
        print(f"‚ö†Ô∏è  Mixed results - {fake_count} model(s) detected fake")
        print(f"   Detected by: {', '.join(result['summary']['detected_by'])}")

    # Individual model outputs
    print("\n" + "="*70)
    print("INDIVIDUAL MODEL PREDICTIONS:")
    print("="*70)

    for model_key, model_data in result['models'].items():
        print(f"\n{'‚îÄ'*70}")
        print(f"ü§ñ {model_data['name']}")
        print(f"{'‚îÄ'*70}")

        # Prediction
        emoji = "üö®" if model_data['is_fake'] else "‚úÖ"
        print(f"{emoji} PREDICTION: {model_data['prediction']}")
        print(f"üìä CONFIDENCE: {model_data['confidence']*100:.2f}%")
        print(f"üéØ SPECIALTY: {model_data['specialty']}")

        if 'preprocessing' in model_data:
            print(f"üîß PREPROCESSING: {model_data['preprocessing']}")

        # Show all probabilities
        if model_data['all_probabilities']:
            print(f"\nüìà CLASS PROBABILITIES:")
            for label, prob in model_data['all_probabilities'].items():
                bar_length = int(prob * 40)
                bar = "‚ñà" * bar_length + "‚ñë" * (40 - bar_length)
                print(f"  {label:30s} {bar} {prob*100:5.2f}%")

    print("\n" + "="*70)
    print("üí° INTERPRETATION GUIDE:")
    print("="*70)
    print("‚Ä¢ FSFM-3C: Look for 'Deepfake', 'Diffusion', or 'Spoofing' classes")
    print("‚Ä¢ CemRoot: High accuracy (95%) with training_match preprocessing")
    print("‚Ä¢ ViT-v2: Strong at traditional deepfakes and ChatGPT images")
    print("\n‚û°Ô∏è  If ANY model detects fake with high confidence, investigate!")
    print("="*70 + "\n")


def main():
    parser = argparse.ArgumentParser(
        description='Ensemble Deepfake Detection - Individual Model Dashboard'
    )

    # Input
    parser.add_argument('--image', type=str, required=True,
                        help='Path to input image')

    # FSFM-3C config
    parser.add_argument('--fsfm_checkpoint', type=str,
                        default='../models/fsfm/checkpoint-min_train_loss.pth',
                        help='Path to FSFM checkpoint-min_train_loss.pth')
    parser.add_argument('--fsfm_mean_std', type=str,
                        default='../models/fsfm/pretrain_ds_mean_std.txt',
                        help='Path to FSFM pretrain_ds_mean_std.txt')

    # CemRoot config
    parser.add_argument('--cemroot_model', type=str,
                        default='../models/cemroot/best_model_effatt.h5',
                        help='Path to CemRoot best_model_effatt.h5')
    parser.add_argument('--cemroot_method', type=str, default='training_match',
                        choices=['training_match', 'simple_norm', 'efficientnet'],
                        help='CemRoot preprocessing method')

    # ViT-v2 config
    parser.add_argument('--vit_model', type=str,
                        default='prithivMLmods/Deep-Fake-Detector-v2-Model',
                        help='ViT model name or path')
    parser.add_argument('--vit_cache_dir', type=str,
                        default='../models/vit-v2',
                        help='ViT cache directory')

    # Device config
    parser.add_argument('--device', type=str, default='cpu',
                        choices=['cuda', 'cpu'],
                        help='Device for PyTorch models')

    args = parser.parse_args()

    # Initialize ensemble
    ensemble = EnsembleDeepfakeDetector(
        fsfm_config={
            'checkpoint': args.fsfm_checkpoint,
            'mean_std': args.fsfm_mean_std,
            'device': args.device
        },
        cemroot_config={
            'model_path': args.cemroot_model,
            'image_size': 128
        },
        vit_config={
            'model_name': args.vit_model,
            'cache_dir': args.vit_cache_dir,
            'device': args.device
        }
    )

    # Run individual predictions
    result = ensemble.predict(
        args.image,
        cemroot_method=args.cemroot_method
    )

    # Print results
    print_ensemble_result(result)


if __name__ == "__main__":
    if len(sys.argv) == 1:
        print("\n" + "="*70)
        print("ENSEMBLE DEEPFAKE DETECTOR - INDIVIDUAL MODEL DASHBOARD")
        print("="*70)
        print("\nShows each model's prediction separately (no voting/aggregation)")
        print("\nModels:")
        print("  1. FSFM-3C - Best for: Spoofing, advanced manipulations")
        print("  2. CemRoot - Best for: Diffusion models, AIGC")
        print("  3. ViT-v2  - Best for: Traditional deepfakes, ChatGPT")
        print("\nUsage:")
        print("  python ensemble_detector.py --image <path_to_image>")
        print("\nExample:")
        print("  python ensemble_detector.py --image test.jpg")
        print("\n" + "="*70)
        print("\nWhy individual outputs?")
        print("  ‚Ä¢ Different models catch different generation methods")
        print("  ‚Ä¢ Voting can hide important detections")
        print("  ‚Ä¢ See which model's specialty matches the image")
        print("  ‚Ä¢ ANY high-confidence fake detection is valuable!")
        print("="*70 + "\n")
    else:
        main()